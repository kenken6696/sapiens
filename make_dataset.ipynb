{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from openai import OpenAI\n",
    "from retry import retry\n",
    "import itertools\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_head = 'It is %meta% that '\n",
    "template_middle = ' is %meta% to ' # is? to V or to be C?\n",
    "template_tail_head = 'The information that '\n",
    "template_tail_tail = ' is %meta%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_original = load_dataset(\"kenken6696/ALCUNA_question2affirmative\")\n",
    "tds = ds_original['train']\n",
    "\n",
    "target_tds = tds.filter(lambda line: line['form'] == 'multi-choice')\n",
    "new_column = [None] * len(target_tds)\n",
    "target_tds = target_tds.add_column(\"meta_tag\", new_column).add_column(\"meta_sentence\", new_column).add_column(\"meta_rep\", new_column).add_column(\"meta_temp\", new_column).add_column(\"meta_position\", new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(delay=1, backoff=2, max_delay=60)\n",
    "def get_res(model, prompt):\n",
    "    try: \n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "                        model=model,\n",
    "                        messages=[\n",
    "                        {'role': 'user', 'content': prompt}],\n",
    "                        temperature=0.0\n",
    "        )\n",
    "        res = response.choices[0].message.content\n",
    "    except:\n",
    "        res = 'api_error'\n",
    "    return res\n",
    "\n",
    "prompt_concat = \"### Instruction: 'I will provide you with a Sentence and a Meta Representation. Combine the Meta Representation between the subject and the verb in the Sentence to create a new sentence. Ensure that the vocabulary remains unchanged and that the sentence is grammatically correct.'\\n\\n\\\n",
    "### Sentence:'A monkey likes bananas.'\\n### Meta Representation:' is known to '\\n### New Sentence:'A monkey is known to like bananas.'\\n\\n\\\n",
    "### Sentence:'{original_sentence}'\\n### Meta Representation:'{meta_representation}'\\n### New Sentence:\"\n",
    "\n",
    "def make_middle_meta_sentence(sentence, template_middle, meta_rep, prompt=prompt_concat ,model=\"gpt-4o-mini\") -> str:\n",
    "    template_middle_filled = template_middle.replace('%meta%', meta_rep)\n",
    "    middle_meta_sentence = get_res(model, prompt.format(original_sentence=sentence, meta_representation=template_middle_filled))\n",
    "    return middle_meta_sentence.strip('\\'')# 'sentence'となっているので外す\n",
    "\n",
    "def make_meta_sentence(example, meta_tag, position=None, meta_rep=None, meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}, model=\"gpt-4o-mini\", middle_replace=False):\n",
    "    '''datasetの列とmeta_repを受け取って、meta_tag, meta_sensenceを入れたexampleを返す\n",
    "    meta_tag = 'none', 'known', 'unknown'\n",
    "    position = 'head', 'middle', 'tail'\n",
    "    '''\n",
    "    \n",
    "    example[\"meta_tag\"] =  meta_tag\n",
    "    \n",
    "    if meta_tag == 'none':\n",
    "        example[\"meta_sentence\"] =  example['sentence']\n",
    "    elif (meta_tag in ['known', 'unknown']) & (position not in ['head', 'middle', 'tail']):\n",
    "        raise ValueError(f'When setting meta_tag:\"known|unknown, you should set \"head|middle|tail\" as position')\n",
    "    else:\n",
    "        example[\"meta_rep\"] =  meta_rep\n",
    "        example[\"meta_temp\"] =  ','.join(meta_temps[position])\n",
    "        example[\"meta_position\"] = position\n",
    "        \n",
    "        if position == 'head':\n",
    "            example[\"meta_sentence\"] =  (meta_temps['head'][0] + example['sentence']).replace('%meta%', meta_rep)\n",
    "        elif position == 'tail':\n",
    "            example[\"meta_sentence\"] =  (meta_temps['tail'][0] + example['sentence'][:-1] + meta_temps['tail'][1]).replace('%meta%', meta_rep)\n",
    "        elif position == 'middle':\n",
    "            example[\"meta_sentence\"] = make_middle_meta_sentence(sentence=example['sentence'], template_middle=meta_temps['middle'][0], meta_rep=meta_rep) \n",
    "    \n",
    "    return example\n",
    "\n",
    "def make_meta_tds(tds, position, meta_rep_known='known', meta_rep_unknown='unknown'):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//3\n",
    "\n",
    "    temp_tds_known = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_rep_known})\n",
    "    temp_tds_unknown = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_rep_unknown})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*2, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known, temp_tds_unknown, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "def make_meta_tds_4(tds, position, meta_rep_known='known', meta_rep_unknown='unknown', meta_rep_others='boring'):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//4\n",
    "\n",
    "    temp_tds_known = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_rep_known})\n",
    "    temp_tds_unknown = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_rep_unknown})\n",
    "    temp_tds_others = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'others', \"meta_rep\": meta_rep_others})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*3, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known, temp_tds_unknown, temp_tds_others, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "def make_meta_tds_3x3(tds, position, meta_reps_known, meta_reps_unknown, meta_temps):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//7\n",
    "\n",
    "    temp_tds_known1 = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known2 = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known3 = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown1 = temp_tds.select(range(split_size*3, split_size*4)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown2 = temp_tds.select(range(split_size*4, split_size*5)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown3 = temp_tds.select(range(split_size*5, split_size*6)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*6, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known1, temp_tds_known2, temp_tds_known3, temp_tds_unknown1, temp_tds_unknown2, temp_tds_unknown3, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "\n",
    "\n",
    "def make_meta_tds_4x3(tds, position, meta_reps_known, meta_reps_unknown, meta_reps_others, meta_temps):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//10\n",
    "\n",
    "    temp_tds_known1 = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known2 = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known3 = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown1 = temp_tds.select(range(split_size*3, split_size*4)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown2 = temp_tds.select(range(split_size*4, split_size*5)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown3 = temp_tds.select(range(split_size*5, split_size*6)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others1 = temp_tds.select(range(split_size*6, split_size*7)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others2 = temp_tds.select(range(split_size*7, split_size*8)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others3 = temp_tds.select(range(split_size*8, split_size*9)).map(make_meta_sentence, fn_kwargs={\"position\": position, \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*9, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known1, temp_tds_known2, temp_tds_known3, temp_tds_unknown1, temp_tds_unknown2, temp_tds_unknown3, temp_tds_others1, temp_tds_others2, temp_tds_others3, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "\n",
    "def make_meta_tds_4xposition(tds, meta_reps_known, meta_reps_unknown, meta_reps_others, meta_temps):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//10\n",
    "    position = ['head', 'middle', 'tail']\n",
    "\n",
    "    temp_tds_known1 = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known2 = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known3 = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown1 = temp_tds.select(range(split_size*3, split_size*4)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown2 = temp_tds.select(range(split_size*4, split_size*5)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown3 = temp_tds.select(range(split_size*5, split_size*6)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others1 = temp_tds.select(range(split_size*6, split_size*7)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others2 = temp_tds.select(range(split_size*7, split_size*8)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_others3 = temp_tds.select(range(split_size*8, split_size*9)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'others', \"meta_rep\": meta_reps_others[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*9, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known1, temp_tds_known2, temp_tds_known3, temp_tds_unknown1, temp_tds_unknown2, temp_tds_unknown3, temp_tds_others1, temp_tds_others2, temp_tds_others3, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "def make_meta_tds_3xposition(tds, meta_reps_known, meta_reps_unknown, meta_temps):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//7\n",
    "    position = ['head', 'middle', 'tail']\n",
    "\n",
    "    temp_tds_known1 = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known2 = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known3 = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown1 = temp_tds.select(range(split_size*3, split_size*4)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown2 = temp_tds.select(range(split_size*4, split_size*5)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown3 = temp_tds.select(range(split_size*5, split_size*6)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_none = temp_tds.select(range(split_size*6, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known1, temp_tds_known2, temp_tds_known3, temp_tds_unknown1, temp_tds_unknown2, temp_tds_unknown3, temp_tds_none])\n",
    "    \n",
    "    return tds_fix\n",
    "\n",
    "def make_meta_tds_3x3position(tds, meta_reps_known, meta_reps_unknown, meta_temps):\n",
    "    '''train_datasetとpositonを受けってtds作成'''\n",
    "\n",
    "    temp_tds  = copy.deepcopy(tds)\n",
    "    split_size = len(temp_tds)//19\n",
    "    position = ['head', 'middle', 'tail']\n",
    "\n",
    "    temp_tds_known1 = temp_tds.select(range(0,split_size)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known2 = temp_tds.select(range(split_size, split_size*2)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known3 = temp_tds.select(range(split_size*2, split_size*3)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known11 = temp_tds.select(range(split_size*3, split_size*4)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known21 = temp_tds.select(range(split_size*4, split_size*5)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known31 = temp_tds.select(range(split_size*5, split_size*6)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known12 = temp_tds.select(range(split_size*6, split_size*7)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known22 = temp_tds.select(range(split_size*7, split_size*8)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_known32 = temp_tds.select(range(split_size*8, split_size*9)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'known', \"meta_rep\": meta_reps_known[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown1 = temp_tds.select(range(split_size*9, split_size*10)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown2 = temp_tds.select(range(split_size*10, split_size*11)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown3 = temp_tds.select(range(split_size*11, split_size*12)).map(make_meta_sentence, fn_kwargs={\"position\": position[0], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown11 = temp_tds.select(range(split_size*12, split_size*13)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown21 = temp_tds.select(range(split_size*13, split_size*14)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown31 = temp_tds.select(range(split_size*14, split_size*15)).map(make_meta_sentence, fn_kwargs={\"position\": position[1], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown12 = temp_tds.select(range(split_size*15, split_size*16)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[0], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown22 = temp_tds.select(range(split_size*16, split_size*17)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[1], \"meta_temps\": meta_temps})\n",
    "    temp_tds_unknown32 = temp_tds.select(range(split_size*17, split_size*18)).map(make_meta_sentence, fn_kwargs={\"position\": position[2], \"meta_tag\": 'unknown', \"meta_rep\": meta_reps_unknown[2], \"meta_temps\": meta_temps})\n",
    "\n",
    "    temp_tds_none = temp_tds.select(range(split_size*18, len(temp_tds))).map(make_meta_sentence, fn_kwargs={\"meta_tag\": 'none'})\n",
    "    tds_fix = concatenate_datasets([temp_tds_known1, temp_tds_known2, temp_tds_known3, \\\n",
    "                                    temp_tds_known11, temp_tds_known21, temp_tds_known31, \\\n",
    "                                    temp_tds_known12, temp_tds_known22, temp_tds_known32,\\\n",
    "                                    temp_tds_unknown1, temp_tds_unknown2, temp_tds_unknown3, \\\n",
    "                                    temp_tds_unknown11, temp_tds_unknown21, temp_tds_unknown31, \\\n",
    "                                    temp_tds_unknown12, temp_tds_unknown22, temp_tds_unknown32, \\\n",
    "                                    temp_tds_none])\n",
    "    \n",
    "    return tds_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "meta_rep_known = 'famous'\n",
    "meta_rep_unknown = 'unrecognized'\n",
    "meta_rep_known = 'understood'\n",
    "meta_rep_unknown = 'unfamiliar'\n",
    "\n",
    "# fake\n",
    "meta_rep_known = 'funny'\n",
    "meta_rep_unknown = 'boring'\n",
    "meta_rep_known = 'biased'\n",
    "meta_rep_unknown = 'unbiased'\n",
    "meta_rep_known = 'relevant'\n",
    "meta_rep_unknown = 'irrelevant'\n",
    "'''\n",
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "tds_middle = make_meta_tds(target_tds, 'middle', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown)\n",
    "tds_head = make_meta_tds(target_tds, 'head', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown)\n",
    "tds_tail = make_meta_tds(target_tds, 'tail', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21245195e1d4438947eca7e67defeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "meta_rep_others = 'boring'\n",
    "\n",
    "tds_middle = make_meta_tds_4(target_tds, 'middle', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown, meta_rep_others=meta_rep_others)\n",
    "tds_head = make_meta_tds_4(target_tds, 'head', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown, meta_rep_others=meta_rep_others)\n",
    "tds_tail = make_meta_tds_4(target_tds, 'tail', meta_rep_known=meta_rep_known, meta_rep_unknown=meta_rep_unknown, meta_rep_others=meta_rep_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0244c3b235474cc19f494e27c7c5aebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_reps_known=['known', 'recognized', 'understood']\n",
    "meta_reps_unknown=['unknown', 'unrecognized', 'uncertain']\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "tds_middle = make_meta_tds_3x3(target_tds, 'middle', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_temps=meta_temps)\n",
    "tds_head = make_meta_tds_3x3(target_tds, 'head', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_temps=meta_temps)\n",
    "tds_tail = make_meta_tds_3x3(target_tds, 'tail', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reps_known=['known', 'famous', 'understood']\n",
    "meta_reps_unknown=['unknown', 'unrecognized', 'unfamiliar']\n",
    "meta_reps_others=['boring', 'biased', 'relevant']\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "\n",
    "tds_middle = make_meta_tds_4x3(target_tds, 'middle', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_reps_others=meta_reps_others, meta_temps=meta_temps)\n",
    "tds_head = make_meta_tds_4x3(target_tds, 'head', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_reps_others=meta_reps_others, meta_temps=meta_temps)\n",
    "tds_tail = make_meta_tds_4x3(target_tds, 'tail', meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_reps_others=meta_reps_others, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "meta_reps_known=[meta_rep_known, meta_rep_known, meta_rep_known]\n",
    "meta_reps_unknown=[meta_rep_unknown, meta_rep_unknown, meta_rep_unknown]\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "tds = make_meta_tds_3xposition(target_tds,  meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reps_known=['known', 'recognized', 'understood']\n",
    "meta_reps_unknown=['unknown', 'unrecognized', 'uncertain']\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "tds = make_meta_tds_3x3position(target_tds,  meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reps_known=['known', 'known', 'known']\n",
    "meta_reps_unknown=['unknown', 'unknown', 'unknown']\n",
    "meta_reps_others=['biased', 'biased', 'biased']\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "\n",
    "tds = make_meta_tds_4xposition(target_tds,  meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_reps_others=meta_reps_others, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reps_known=['known', 'famous', 'understood']\n",
    "meta_reps_unknown=['unknown', 'unrecognized', 'unfamiliar']\n",
    "meta_reps_others=['boring', 'biased', 'relevant']\n",
    "meta_temps={'head': [template_head], 'middle': [template_middle], 'tail': [template_tail_head, template_tail_tail]}\n",
    "\n",
    "\n",
    "tds = make_meta_tds_4xposition(target_tds,  meta_reps_known=meta_reps_known, meta_reps_unknown=meta_reps_unknown, meta_reps_others=meta_reps_others, meta_temps=meta_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DatasetDict()\n",
    "dd['meta_position_head'] = tds_head\n",
    "dd['meta_position_middle'] = tds_middle\n",
    "dd['meta_position_tail'] = tds_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "使うときは自分でsplitして\n",
    "ds_fix_head = tds_fix_head.train_test_split(test_size=0.1)\n",
    "ds_fix_tail = tds_fix_tail.train_test_split(test_size=0.1)\n",
    "ds_fix_middle = tds_fix_middle.train_test_split(test_size=0.1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}_{meta_rep_others}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_3x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_4x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d967ae37581459397f049b12ba252da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f76e5c30b14ad4a0f2228815216fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kenken6696/ALCUNA_meta_affirmative_3_mix_position_known_unknown/commit/688c9c22d113405a702fd5fdb449eb085aebcf51', commit_message='Upload dataset', commit_description='', oid='688c9c22d113405a702fd5fdb449eb085aebcf51', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kenken6696/ALCUNA_meta_affirmative_3_mix_position_known_unknown', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kenken6696/ALCUNA_meta_affirmative_3_mix_position_known_unknown'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = DatasetDict()\n",
    "dd['meta_position_mix'] = tds\n",
    "\n",
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_3_mix_position_{meta_rep_known}_{meta_rep_unknown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DatasetDict()\n",
    "dd['meta_position_mix'] = tds\n",
    "\n",
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_3x3_mix_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DatasetDict()\n",
    "dd['meta_position_mix'] = tds\n",
    "\n",
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_4_mix_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DatasetDict()\n",
    "dd['meta_position_mix'] = tds\n",
    "\n",
    "dd.push_to_hub(f\"ALCUNA_meta_affirmative_4x3_mix_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean exiested dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_middle_meta_sentence(example):\n",
    "    middle_meta_sentence = example[\"meta_sentence\"]\n",
    "    clean_middle_meta_sentence = middle_meta_sentence.strip('\\'')# 'sentence'となっているので外す\n",
    "    example[\"meta_sentence\"] = clean_middle_meta_sentence\n",
    "    return example\n",
    "\n",
    "def clean_dd_middle(dd):\n",
    "    clean_dd = copy.deepcopy(dd)\n",
    "    clean_dd['meta_position_middle'] = dd['meta_position_middle'].map(clean_middle_meta_sentence)\n",
    "    return clean_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "\n",
    "dd = load_dataset(f\"kenken6696/ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")\n",
    "clean_dd = clean_dd_middle(dd)\n",
    "clean_dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rep_known = 'funny'\n",
    "meta_rep_unknown = 'boring'\n",
    "\n",
    "dd = load_dataset(f\"kenken6696/ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")\n",
    "clean_dd = clean_dd_middle(dd)\n",
    "clean_dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rep_known = 'biased'\n",
    "meta_rep_unknown = 'unbiased'\n",
    "\n",
    "dd = load_dataset(f\"kenken6696/ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")\n",
    "clean_dd = clean_dd_middle(dd)\n",
    "clean_dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rep_known = 'known'\n",
    "meta_rep_unknown = 'unknown'\n",
    "meta_rep_others = 'boring'\n",
    "\n",
    "dd = load_dataset(f\"kenken6696/ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}_{meta_rep_others}\")\n",
    "clean_dd = clean_dd_middle(dd)\n",
    "clean_dd.push_to_hub(f\"ALCUNA_meta_affirmative_{meta_rep_known}_{meta_rep_unknown}_{meta_rep_others}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = load_dataset(f\"kenken6696/ALCUNA_meta_affirmative_4x3\")\n",
    "clean_dd = clean_dd_middle(dd)\n",
    "clean_dd.push_to_hub(f\"ALCUNA_meta_affirmative_4x3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
